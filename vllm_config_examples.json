{
  "configs": {
    "lightweight": {
      "description": "Легкие модели для слабых систем",
      "models": [
        {
          "model_path": "microsoft/DialoGPT-small",
          "display_name": "DialoGPT Small",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.2,
          "max_model_len": 512,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models"
        },
        {
          "model_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
          "display_name": "TinyLlama 1.1B",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.3,
          "max_model_len": 1024,
          "port": 8001,
          "download_to_local": true,
          "local_models_dir": "./models"
        }
      ]
    },
    
    "medium_power": {
      "description": "Модели средней мощности для обычных систем",
      "models": [
        {
          "model_path": "microsoft/DialoGPT-medium",
          "display_name": "DialoGPT Medium",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.6,
          "max_model_len": 1024,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models"
        },
        {
          "model_path": "Qwen/Qwen2-0.5B-Instruct",
          "display_name": "Qwen2 0.5B",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.4,
          "max_model_len": 2048,
          "port": 8001,
          "download_to_local": true,
          "local_models_dir": "./models"
        },
        {
          "model_path": "Qwen/Qwen2-1.5B-Instruct",
          "display_name": "Qwen2 1.5B",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.7,
          "max_model_len": 4096,
          "port": 8002,
          "download_to_local": true,
          "local_models_dir": "./models"
        }
      ]
    },
    
    "high_performance": {
      "description": "Мощные модели для производительных систем",
      "models": [
        {
          "model_path": "microsoft/DialoGPT-large",
          "display_name": "DialoGPT Large",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.8,
          "max_model_len": 1024,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models"
        },
        {
          "model_path": "Qwen/Qwen2-7B-Instruct",
          "display_name": "Qwen2 7B",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9,
          "max_model_len": 4096,
          "port": 8001,
          "download_to_local": true,
          "local_models_dir": "./models"
        }
      ]
    },
    
    "russian_models": {
      "description": "Модели с хорошей поддержкой русского языка",
      "models": [
        {
          "model_path": "IlyaGusev/saiga_mistral_7b_gguf",
          "display_name": "Saiga Mistral 7B",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.8,
          "max_model_len": 4096,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models"
        },
        {
          "model_path": "ai-forever/rugpt3small_based_on_gpt2",
          "display_name": "ruGPT-3 Small",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.5,
          "max_model_len": 1024,
          "port": 8001,
          "download_to_local": true,
          "local_models_dir": "./models"
        }
      ]
    },
    
    "chat_specialized": {
      "description": "Специализированные чат-модели",
      "models": [
        {
          "model_path": "microsoft/DialoGPT-medium",
          "display_name": "DialoGPT Medium Chat",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.6,
          "max_model_len": 1024,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models",
          "temperature": 0.8
        },
        {
          "model_path": "facebook/blenderbot-400M-distill",
          "display_name": "BlenderBot 400M",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.4,
          "max_model_len": 512,
          "port": 8001,
          "download_to_local": true,
          "local_models_dir": "./models",
          "temperature": 0.9
        }
      ]
    },
    
    "single_model_test": {
      "description": "Тест одной модели",
      "models": [
        {
          "model_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
          "display_name": "TinyLlama Test",
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.4,
          "max_model_len": 2048,
          "port": 8000,
          "download_to_local": true,
          "local_models_dir": "./models",
          "temperature": 0.7
        }
      ]
    }
  },
  
  "system_requirements": {
    "lightweight": {
      "min_gpu_memory_gb": 2,
      "min_system_memory_gb": 4,
      "description": "Минимальные требования"
    },
    "medium_power": {
      "min_gpu_memory_gb": 6,
      "min_system_memory_gb": 8,
      "description": "Рекомендуемые требования"
    },
    "high_performance": {
      "min_gpu_memory_gb": 12,
      "min_system_memory_gb": 16,
      "description": "Высокопроизводительная система"
    }
  },
  
  "tips": {
    "gpu_memory_optimization": [
      "Уменьшите gpu_memory_utilization до 0.4-0.6 для экономии памяти",
      "Используйте max_model_len не более 2048 для маленьких моделей",
      "Запускайте модели последовательно, а не параллельно"
    ],
    "model_selection": [
      "DialoGPT хорош для диалогов на английском языке",
      "Qwen2 модели хорошо работают с инструкциями",
      "TinyLlama - самая легкая модель для тестирования",
      "Для русского языка попробуйте ruGPT или Saiga модели"
    ],
    "performance": [
      "Используйте SSD для хранения моделей",
      "Закройте ненужные приложения перед запуском",
      "Мониторьте температуру GPU во время работы"
    ]
  }
} 