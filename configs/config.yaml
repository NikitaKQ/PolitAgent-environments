defaults:
  - model: ollama
  - game: askguess
  - experiment: default
  - _self_

hydra:
  run:
    dir: ./outputs/${experiment.name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: ./multirun/${experiment.name}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra:job.num}

experiment:
  name: "politagent_benchmark"
  description: "Benchmarking LLM agents in game environments"
  author: "PolitAgent Team"
  tags: []

benchmark:
  workers: 1
  runs_per_game: 1
  max_phrases: null
  debug: false
  use_llm_evaluation: false

output:
  save_logs: true
  save_results: true
  results_format: "json"
  log_level: "INFO"

seed: 42
deterministic: true 