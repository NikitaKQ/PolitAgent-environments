#!/bin/bash

# vLLM Benchmark Runner Script
# –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ vLLM

set -e  # –í—ã—Ö–æ–¥–∏—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ü–≤–µ—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
check_dependencies() {
    print_status "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π..."
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
    if ! command -v python &> /dev/null; then
        print_error "Python –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Python 3.8+"
        exit 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ pip
    if ! command -v pip &> /dev/null; then
        print_error "pip –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pip"
        exit 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ vLLM
    if ! python -c "import vllm" &> /dev/null; then
        print_warning "vLLM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏..."
        pip install -r requirements_vllm.txt
    fi
    
    print_success "–í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –ø–æ—Ä—è–¥–∫–µ"
}

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
setup_directories() {
    print_status "–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π..."
    mkdir -p models
    mkdir -p vllm_benchmark_results
    print_success "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–Ω—ã"
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
check_gpu() {
    print_status "–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU..."
    if python -c "import torch; print(f'CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}')" | grep -q "True"; then
        print_success "GPU –¥–æ—Å—Ç—É–ø–Ω–∞"
        if command -v nvidia-smi &> /dev/null; then
            print_status "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU:"
            nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits
        fi
    else
        print_warning "GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU (–º–µ–¥–ª–µ–Ω–Ω–æ)"
    fi
}

# –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
show_help() {
    echo "vLLM Benchmark Runner"
    echo ""
    echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:"
    echo "  $0 [–∫–æ–º–∞–Ω–¥–∞] [–ø–∞—Ä–∞–º–µ—Ç—Ä—ã]"
    echo ""
    echo "–ö–æ–º–∞–Ω–¥—ã:"
    echo "  setup                    - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
    echo "  example                  - –ó–∞–ø—É—Å–∫ –ª–µ–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"
    echo "  advanced                 - –ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π"
    echo "  model <model_id>         - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"
    echo "  custom <config_file>     - –ó–∞–ø—É—Å–∫ —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π"
    echo "  monitor                  - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"
    echo "  clean                    - –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"
    echo "  help                     - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É"
    echo ""
    echo "–ü—Ä–∏–º–µ—Ä—ã:"
    echo "  $0 example                                    # –õ–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏"
    echo "  $0 model TinyLlama/TinyLlama-1.1B-Chat-v1.0  # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å"
    echo "  $0 advanced                                   # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏"
    echo ""
}

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
setup() {
    print_status "üöÄ –ù–∞—á–∏–Ω–∞–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫—É..."
    check_dependencies
    setup_directories
    check_gpu
    print_success "‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
}

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π
run_example() {
    print_status "üß™ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ —Å –ª–µ–≥–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏..."
    python scripts/vllm_benchmark_cli.py --preset example --log-level INFO
    print_success "‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!"
}

# –ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π
run_advanced() {
    print_status "üöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏..."
    print_warning "–í–Ω–∏–º–∞–Ω–∏–µ: –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤ GPU!"
    python scripts/vllm_benchmark_cli.py --preset advanced --log-level INFO
    print_success "‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!"
}

# –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
run_single_model() {
    if [ -z "$1" ]; then
        print_error "–£–∫–∞–∂–∏—Ç–µ ID –º–æ–¥–µ–ª–∏. –ü—Ä–∏–º–µ—Ä: TinyLlama/TinyLlama-1.1B-Chat-v1.0"
        exit 1
    fi
    
    print_status "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: $1"
    python scripts/vllm_benchmark_cli.py --model "$1" --log-level INFO
    print_success "‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
}

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
monitor_resources() {
    print_status "üìä –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤..."
    print_status "–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞"
    
    if command -v nvidia-smi &> /dev/null; then
        print_status "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU..."
        watch -n 2 'echo "=== GPU Status ===" && nvidia-smi --query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv && echo "" && echo "=== System Memory ===" && free -h'
    else
        print_status "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤..."
        watch -n 2 'echo "=== System Resources ===" && free -h && echo "" && echo "=== Top Processes ===" && top -bn1 | head -20'
    fi
}

# –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
clean() {
    print_status "üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤..."
    
    # –£–¥–∞–ª—è–µ–º –ª–æ–≥–∏ —Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π
    find . -name "*.log" -mtime +7 -delete 2>/dev/null || true
    
    # –û—á–∏—â–∞–µ–º –∫—ç—à Python
    find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
    find . -name "*.pyc" -delete 2>/dev/null || true
    
    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—Ä–æ —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    if [ -d "models" ]; then
        echo -n "–£–¥–∞–ª–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏? [y/N]: "
        read -r response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            rm -rf models/*
            print_success "–ú–æ–¥–µ–ª–∏ —É–¥–∞–ª–µ–Ω—ã"
        fi
    fi
    
    print_success "‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
}

# –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
main() {
    case "${1:-help}" in
        setup)
            setup
            ;;
        example)
            check_dependencies
            setup_directories
            run_example
            ;;
        advanced)
            check_dependencies
            setup_directories
            run_advanced
            ;;
        model)
            check_dependencies
            setup_directories
            run_single_model "$2"
            ;;
        monitor)
            monitor_resources
            ;;
        clean)
            clean
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            print_error "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: $1"
            echo ""
            show_help
            exit 1
            ;;
    esac
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
if [ $# -eq 0 ]; then
    show_help
    exit 0
fi

# –ó–∞–ø—É—Å–∫ –≥–ª–∞–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
main "$@" 