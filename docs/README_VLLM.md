# ü§ñ vLLM Benchmark –¥–ª—è PolitAgent Environments

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ HuggingFace —á–µ—Ä–µ–∑ vLLM –Ω–∞ –∏–≥—Ä–∞—Ö —Å –ò–ò –∞–≥–µ–Ω—Ç–∞–º–∏.

## ‚ú® –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- üöÄ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞** –º–æ–¥–µ–ª–µ–π –∏–∑ HuggingFace Hub
- üíæ **–õ–æ–∫–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ** –º–æ–¥–µ–ª–µ–π –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
- ‚ö° **vLLM –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- üéÆ **5 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–≥—Ä** –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- üìä **–ü–æ–¥—Ä–æ–±–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞** –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
- üîß **–ì–∏–±–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** –ø–æ–¥ –ª—é–±—ã–µ —Ä–µ—Å—É—Ä—Å—ã
- üì± **–£–¥–æ–±–Ω—ã–π CLI** —Å bash-—Å–∫—Ä–∏–ø—Ç–∞–º–∏

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –°—É–ø–µ—Ä-–±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ (3 –∫–æ–º–∞–Ω–¥—ã)

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
./run_vllm_benchmark.sh setup

# 2. –ó–∞–ø—É—Å–∫ –ª–µ–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
./run_vllm_benchmark.sh example

# 3. –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
ls vllm_benchmark_results/
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏

```bash
# TinyLlama (–ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å ~1GB)
./run_vllm_benchmark.sh model TinyLlama/TinyLlama-1.1B-Chat-v1.0

# DialoGPT –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
./run_vllm_benchmark.sh model microsoft/DialoGPT-medium

# Qwen –¥–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
./run_vllm_benchmark.sh model Qwen/Qwen2-0.5B-Instruct
```

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ
- Python 3.8+
- 4GB RAM
- 2GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ
- Python 3.10+
- 8GB RAM + 4GB VRAM
- 10GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- CUDA-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è GPU

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
```bash
./run_vllm_benchmark.sh setup
```

### –†—É—á–Ω–∞—è
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements_vllm.txt

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
mkdir -p models vllm_benchmark_results

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
python -c "import vllm; print('vLLM –≥–æ—Ç–æ–≤!')"
```

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### CLI –∫–æ–º–∞–Ω–¥—ã

```bash
# –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
./run_vllm_benchmark.sh help

# –õ–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ (< 2GB –∫–∞–∂–¥–∞—è)
./run_vllm_benchmark.sh example

# –ú–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏ (—Ç—Ä–µ–±—É–µ—Ç >8GB VRAM)
./run_vllm_benchmark.sh advanced

# –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
./run_vllm_benchmark.sh model <huggingface_model_id>

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
./run_vllm_benchmark.sh monitor

# –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
./run_vllm_benchmark.sh clean
```

### Python API

```python
from scripts.vllm_benchmark_cli import SequentialVLLMBenchmark, VLLMModelConfig

# –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–Ω—á–º–∞—Ä–∫–∞
benchmark = SequentialVLLMBenchmark()

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
model_config = VLLMModelConfig(
    model_path="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    display_name="TinyLlama Test",
    download_to_local=True,
    local_models_dir="./models"
)
benchmark.add_vllm_model(model_config)

# –ó–∞–ø—É—Å–∫
import asyncio
summary = asyncio.run(benchmark.run_sequential_benchmark())
```

## üéÆ –¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∏–≥—Ä—ã

| –ò–≥—Ä–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –†–∞—É–Ω–¥—ã | –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è |
|------|----------|--------|---------------|
| **Diplomacy** | –î–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è | 3 | –ü–µ—Ä–µ–≥–æ–≤–æ—Ä—ã, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è |
| **Beast** | –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–∞ | 4 | –î–µ–¥—É–∫—Ü–∏—è, –ª–æ–≥–∏–∫–∞ |
| **Spyfall** | –î–µ—Ç–µ–∫—Ç–∏–≤–Ω–∞—è –∏–≥—Ä–∞ | 4 | –û–±–º–∞–Ω, –∞–Ω–∞–ª–∏–∑ |
| **AskGuess** | –í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã | 6 | –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è |
| **ToFuKingdom** | –†–æ–ª–µ–≤–∞—è –∏–≥—Ä–∞ | 5 | –ü–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ |

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏

- **Overall Score** - –û–±—â–∏–π –±–∞–ª–ª –º–æ–¥–µ–ª–∏ (0-100)
- **Success Rate** - –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∏–≥—Ä
- **Response Time** - –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—Å–µ–∫)
- **Game Performance** - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –∏–≥—Ä–∞–º
- **Memory Usage** - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU/RAM

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```
vllm_benchmark_results/
‚îú‚îÄ‚îÄ TinyLlama_1.1B_Chat/                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ results_20240101_123456.json       # –ü–æ–¥—Ä–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îî‚îÄ‚îÄ report_20240101_123456.md          # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
‚îú‚îÄ‚îÄ DialoGPT_Medium/
‚îÇ   ‚îú‚îÄ‚îÄ results_20240101_134567.json
‚îÇ   ‚îî‚îÄ‚îÄ report_20240101_134567.md
‚îú‚îÄ‚îÄ vllm_benchmark_summary_1704123456.json # –°–≤–æ–¥–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
‚îî‚îÄ‚îÄ vllm_benchmark.log                     # –õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞–±–æ—Ä—ã

| –ù–∞–±–æ—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è |
|-------|----------|------------|
| `example` | –õ–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ | 2GB VRAM |
| `advanced` | –ú–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏ | 8GB+ VRAM |

### –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–°–æ–∑–¥–∞–π—Ç–µ JSON —Ñ–∞–π–ª —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π:

```json
{
  "model_path": "your-org/your-model",
  "display_name": "–í–∞—à–∞ –ú–æ–¥–µ–ª—å",
  "tensor_parallel_size": 1,
  "gpu_memory_utilization": 0.8,
  "max_model_len": 4096,
  "download_to_local": true,
  "local_models_dir": "./models"
}
```

–°–º. `vllm_config_examples.json` –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.

## üõ† –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –î–ª—è —Å–ª–∞–±—ã—Ö —Å–∏—Å—Ç–µ–º
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∞–ª–µ–Ω—å–∫–∏–µ –º–æ–¥–µ–ª–∏
./run_vllm_benchmark.sh model microsoft/DialoGPT-small

# –£–º–µ–Ω—å—à–∏—Ç–µ gpu_memory_utilization –≤ –∫–æ–Ω—Ñ–∏–≥–µ –¥–æ 0.4-0.6
```

### –î–ª—è –º–æ—â–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
```bash
# –ó–∞–ø—É—Å–∫–∞–π—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏
./run_vllm_benchmark.sh advanced

# –£–≤–µ–ª–∏—á—å—Ç–µ max_model_len –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
```

### –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏
- –ó–∞–ø—É—Å–∫–∞–π—Ç–µ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `tensor_parallel_size=1`
- –û—á–∏—â–∞–π—Ç–µ –∫—ç—à –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏

## üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –í–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
./run_vllm_benchmark.sh monitor

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ nvidia-smi
watch -n 1 nvidia-smi
```

### –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```python
import json

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
with open('vllm_benchmark_results/summary.json') as f:
    data = json.load(f)

# –ê–Ω–∞–ª–∏–∑
for result in data['results']:
    if result['status'] == 'completed':
        print(f"{result['model_name']}: {result['ratings'][0]['overall_score']}")
```

## üÜò Troubleshooting

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

**CUDA out of memory**
```bash
# –†–µ—à–µ–Ω–∏–µ: —É–º–µ–Ω—å—à–∏—Ç–µ gpu_memory_utilization
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
```

**–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ HuggingFace —Ç–æ–∫–µ–Ω
export HF_TOKEN="your_token_here"
```

**vLLM API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**
```bash
# –î–æ–∂–¥–∏—Ç–µ—Å—å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ (–¥–æ 5 –º–∏–Ω—É—Ç)
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: tail -f vllm_benchmark.log
```

**–ù–µ—Ç GPU**
```bash
# vLLM –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ CPU
# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç –Ω–∏–∂–µ, –Ω–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è
```

## üìà –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö
- `microsoft/DialoGPT-small` (~300MB)
- `TinyLlama/TinyLlama-1.1B-Chat-v1.0` (~1GB)

### –î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- `microsoft/DialoGPT-medium` (~800MB)
- `Qwen/Qwen2-0.5B-Instruct` (~500MB)

### –î–ª—è —Å–µ—Ä—å–µ–∑–Ω–æ–π —Ä–∞–±–æ—Ç—ã
- `microsoft/DialoGPT-large` (~3GB)
- `Qwen/Qwen2-1.5B-Instruct` (~1.5GB)
- `Qwen/Qwen2-7B-Instruct` (~7GB)

### –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ
- `ai-forever/rugpt3small_based_on_gpt2`
- `IlyaGusev/saiga_mistral_7b_gguf`

## ü§ù –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –° —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º benchmark_runner
```python
# vLLM –±–µ–Ω—á–º–∞—Ä–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π
from scripts.benchmark_runner import BenchmarkRunner
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
```

### –° –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
```python
# –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
# JSON, CSV, Excel –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- üìñ [–ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](VLLM_SETUP.md)
- üöÄ [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](QUICK_START.md)
- ‚öôÔ∏è [–ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π](vllm_config_examples.json)
- üêõ [–û—Ç—á–µ—Ç—ã –æ–± –æ—à–∏–±–∫–∞—Ö](https://github.com/your-repo/issues)

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.

---

**üéâ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!** –ó–∞–ø—É—Å—Ç–∏—Ç–µ `./run_vllm_benchmark.sh setup` –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã. 